{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:59:02.162568Z",
     "iopub.status.busy": "2025-05-05T12:59:02.162302Z",
     "iopub.status.idle": "2025-05-05T12:59:11.991664Z",
     "shell.execute_reply": "2025-05-05T12:59:11.990828Z",
     "shell.execute_reply.started": "2025-05-05T12:59:02.162542Z"
    },
    "id": "hGgrXaODvtnQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights, convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:59:11.993374Z",
     "iopub.status.busy": "2025-05-05T12:59:11.992904Z",
     "iopub.status.idle": "2025-05-05T12:59:12.011856Z",
     "shell.execute_reply": "2025-05-05T12:59:12.010924Z",
     "shell.execute_reply.started": "2025-05-05T12:59:11.993349Z"
    },
    "id": "Bly-2KXtxgGG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RegionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data['Region_ID'] = self.data['Region_ID'] - 1  # Convert 1–15 to 0–14\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['filename']\n",
    "        label = int(self.data.iloc[idx]['Region_ID'])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.resize((256, 256))  # Ensure resizing to 256x256\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# ------------------------------\n",
    "# Model Definition\n",
    "# ------------------------------\n",
    "def get_model(model_name='convnext_tiny', num_classes=15, unfreeze_last=False, dropout_rate=0.3, stochastic_depth_prob=0.3):\n",
    "    if model_name == 'resnet50':\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        model = resnet50(weights=weights)\n",
    "        in_features = model.fc.in_features\n",
    "        \n",
    "        # Add dropout before final FC layer\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "        if unfreeze_last:\n",
    "            # Freeze all layers first\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Unfreeze only last block: layer4 and fc\n",
    "            for param in model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    elif model_name == 'convnext_tiny':\n",
    "            weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
    "            model = convnext_tiny(weights=weights)\n",
    "            apply_stochastic_depth(model, stochastic_depth_prob)\n",
    "            in_features = model.classifier[2].in_features\n",
    "        \n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.LayerNorm(in_features, eps=1e-6),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )\n",
    "\n",
    "    elif model_name == 'efficientnet_b2':\n",
    "        model = models.efficientnet_b2(weights='IMAGENET1K_V1')\n",
    "        in_features = model.classifier[1].in_features\n",
    "        \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate, inplace=True),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "        if unfreeze_last:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Unfreeze last block and classifier\n",
    "            for param in model.features[-3].parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def apply_stochastic_depth(module, drop_prob):\n",
    "    for name, submodule in module.named_modules():\n",
    "        if isinstance(submodule, nn.Dropout):\n",
    "            submodule.p = drop_prob\n",
    "\n",
    "# ------------------------------\n",
    "# Training Function with best model tracking\n",
    "# ------------------------------\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, config_str=\"\"):\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_save_path = f'model_{config_str}_{timestamp}'\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step() # for cyclelr scheduler\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss/len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "        val_accuracy = evaluate_model(model, val_loader, device)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Save the model if it has the best validation accuracy so far\n",
    "        if val_accuracy > best_acc:\n",
    "            best_acc = val_accuracy\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            # Save the best model for this specific epoch\n",
    "            torch.save(model.state_dict(), f\"{model_save_path}/best_epoch_{epoch+1}_acc_{val_accuracy:.4f}.pth\")\n",
    "            print(f\"New best model saved! Epoch {epoch+1} with accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "        if scheduler:\n",
    "            scheduler.step(val_accuracy)\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    print(f\"Best val accuracy: {best_acc:.4f} at epoch {best_epoch+1}\")\n",
    "    \n",
    "    return {'train_loss': train_losses, 'val_accuracy': val_accuracies, 'best_accuracy': best_acc, 'best_epoch': best_epoch}\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation Function with accuracy return\n",
    "# ------------------------------\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:59:12.012912Z",
     "iopub.status.busy": "2025-05-05T12:59:12.012662Z",
     "iopub.status.idle": "2025-05-05T12:59:12.046805Z",
     "shell.execute_reply": "2025-05-05T12:59:12.046189Z",
     "shell.execute_reply.started": "2025-05-05T12:59:12.012884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_hyperparameter_combinations(train_img_dir, train_csv, val_img_dir, val_csv):\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # For debugging\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define transforms\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = RegionDataset(train_csv, train_img_dir, transform=train_transforms)\n",
    "    val_dataset = RegionDataset(val_csv, val_img_dir, transform=val_transforms)\n",
    "    \n",
    "    # Define hyperparameter grid\n",
    "    hyperparams = {\n",
    "        'learning_rate': [1e-4],\n",
    "        'epochs': [50],\n",
    "        'dropout_rate': [0.3],\n",
    "        'stochastic_depth_prob': [0.3],\n",
    "        'batch_size': [32]  # Keep batch size fixed for now, but can be varied if needed\n",
    "    }\n",
    "    \n",
    "    # Generate all combinations of hyperparameters\n",
    "    keys = list(hyperparams.keys())\n",
    "    values = list(hyperparams.values())\n",
    "    combinations = list(itertools.product(*values))\n",
    "    \n",
    "    results = {}\n",
    "    best_accuracy = 0\n",
    "    best_config = None\n",
    "    best_model_state = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Create a timestamp for saving results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create results dataframe to track all experiments\n",
    "    results_df = pd.DataFrame(columns=[\n",
    "        'learning_rate', 'epochs', 'dropout_rate', 'stochastic_depth_prob', \n",
    "        'batch_size', 'final_accuracy', 'best_accuracy', 'best_epoch'\n",
    "    ])\n",
    "    \n",
    "    for i, combination in enumerate(combinations):\n",
    "        config = {keys[j]: combination[j] for j in range(len(keys))}\n",
    "        \n",
    "        # Create config string for display and tracking\n",
    "        config_str = f\"LR={config['learning_rate']}_E={config['epochs']}_D={config['dropout_rate']}_SDP={config['stochastic_depth_prob']}_BS={config['batch_size']}\"\n",
    "        print(f\"\\n--- Testing Configuration {i+1}/{len(combinations)}: {config_str} ---\")\n",
    "        \n",
    "        # Create data loaders with current batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
    "        \n",
    "        # Create model with current hyperparameters\n",
    "        model = get_model(\n",
    "            model_name='convnext_tiny',\n",
    "            num_classes=15,\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            stochastic_depth_prob=config['stochastic_depth_prob']\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Training setup\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',         # Reduce LR when the monitored quantity stops decreasing\n",
    "            factor=0.5,         # Multiply LR by this factor when reducing\n",
    "            patience=1,         # Number of epochs with no improvement after which LR will be reduced\n",
    "            verbose=True,       # Print a message when LR is reduced\n",
    "            min_lr=1e-6         # Minimum LR\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer, scheduler, device, \n",
    "            num_epochs=config['epochs'], config_str=config_str\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        results[config_str] = history\n",
    "        \n",
    "        # Update results dataframe\n",
    "        best_accuracy_this_run = history['best_accuracy']\n",
    "        final_accuracy = history['val_accuracy'][-1]\n",
    "        best_epoch = history['best_epoch']\n",
    "        \n",
    "        new_row = {\n",
    "            'learning_rate': config['learning_rate'],\n",
    "            'epochs': config['epochs'],\n",
    "            'dropout_rate': config['dropout_rate'],\n",
    "            'stochastic_depth_prob': config['stochastic_depth_prob'],\n",
    "            'batch_size': config['batch_size'],\n",
    "            'final_accuracy': final_accuracy,\n",
    "            'best_accuracy': best_accuracy_this_run,\n",
    "            'best_epoch': best_epoch + 1  # +1 because epochs are 0-indexed in code\n",
    "        }\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        # Check if this is the best configuration so far\n",
    "        if best_accuracy_this_run > best_accuracy:\n",
    "            best_accuracy = best_accuracy_this_run\n",
    "            best_config = config\n",
    "            # We don't need to save model state here because it's already saved during training\n",
    "            best_model_path = f\"model_{config_str}_{timestamp}/best_epoch_{best_epoch+1}_acc_{best_accuracy_this_run:.4f}.pth\"\n",
    "            print(f\"New best configuration found: {config_str}\")\n",
    "            print(f\"Best model path: {best_model_path}\")\n",
    "        \n",
    "        # Intermediate save of results\n",
    "        results_df.to_csv(f'hyperparameter_results_{timestamp}.csv', index=False)\n",
    "        \n",
    "        # Clean up to save memory\n",
    "        del model, optimizer, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Final save of results\n",
    "    results_df.to_csv(f'hyperparameter_results_{timestamp}.csv', index=False)\n",
    "    \n",
    "    print(\"\\n--- Best Configuration ---\")\n",
    "    print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
    "    for param, value in best_config.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best model path: {best_model_path}\")\n",
    "    \n",
    "    return results, results_df, best_config, best_model_path\n",
    "\n",
    "# ------------------------------\n",
    "# Plotting Functions\n",
    "# ------------------------------\n",
    "def plot_results(results, results_df):\n",
    "    # 1. Plot all validation accuracy curves\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    for config, history in results.items():\n",
    "        plt.plot(history['val_accuracy'], label=config)\n",
    "    plt.title('Validation Accuracy for All Configurations')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='x-small')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 2. Plot top 3 configurations\n",
    "    plt.subplot(2, 2, 2)\n",
    "    top_configs = results_df.sort_values('best_accuracy', ascending=False).head(3)\n",
    "    \n",
    "    for _, row in top_configs.iterrows():\n",
    "        config_str = f\"LR={row['learning_rate']}_E={row['epochs']}_D={row['dropout_rate']}_SDP={row['stochastic_depth_prob']}_BS={row['batch_size']}\"\n",
    "        plt.plot(results[config_str]['val_accuracy'], label=config_str)\n",
    "    \n",
    "    plt.title('Top 3 Configurations by Best Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize='small')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 3. Heatmap of dropout rate vs learning rate (using best accuracy)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    try:\n",
    "        pivot_data = results_df.pivot_table(\n",
    "            values='best_accuracy', \n",
    "            index='dropout_rate', \n",
    "            columns='learning_rate'\n",
    "        )\n",
    "        plt.imshow(pivot_data, cmap='viridis', aspect='auto')\n",
    "        plt.colorbar(label='Best Accuracy')\n",
    "        plt.title('Dropout Rate vs Learning Rate')\n",
    "        plt.xlabel('Learning Rate Index')\n",
    "        plt.ylabel('Dropout Rate Index')\n",
    "        plt.xticks(range(len(pivot_data.columns)), pivot_data.columns)\n",
    "        plt.yticks(range(len(pivot_data.index)), pivot_data.index)\n",
    "    except:\n",
    "        plt.text(0.5, 0.5, \"Not enough data for heatmap\", ha='center', va='center')\n",
    "        plt.title('Dropout Rate vs Learning Rate (Error)')\n",
    "    \n",
    "    # 4. Stochastic depth prob vs epochs\n",
    "    plt.subplot(2, 2, 4)\n",
    "    try:\n",
    "        pivot_data = results_df.pivot_table(\n",
    "            values='best_accuracy', \n",
    "            index='stochastic_depth_prob', \n",
    "            columns='epochs'\n",
    "        )\n",
    "        plt.imshow(pivot_data, cmap='viridis', aspect='auto')\n",
    "        plt.colorbar(label='Best Accuracy')\n",
    "        plt.title('Stochastic Depth Prob vs Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Stochastic Depth Prob')\n",
    "        plt.xticks(range(len(pivot_data.columns)), pivot_data.columns)\n",
    "        plt.yticks(range(len(pivot_data.index)), pivot_data.index)\n",
    "    except:\n",
    "        plt.text(0.5, 0.5, \"Not enough data for heatmap\", ha='center', va='center')\n",
    "        plt.title('Stochastic Depth Prob vs Epochs (Error)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    plt.savefig(f'hyperparameter_comparison_{timestamp}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary table of results sorted by best accuracy\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sorted_df = results_df.sort_values('best_accuracy', ascending=False)\n",
    "    \n",
    "    # Plot a horizontal bar chart of best accuracies\n",
    "    plt.barh(range(len(sorted_df)), sorted_df['best_accuracy'])\n",
    "    # Add labels with configuration details\n",
    "    config_labels = [f\"LR={row['learning_rate']}, D={row['dropout_rate']}, SDP={row['stochastic_depth_prob']}, E={row['best_epoch']}/{row['epochs']}\" \n",
    "                     for _, row in sorted_df.iterrows()]\n",
    "    plt.yticks(range(len(sorted_df)), config_labels)\n",
    "    plt.xlabel('Best Validation Accuracy')\n",
    "    plt.title('Hyperparameter Configurations Ranked by Best Accuracy')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'hyperparameter_ranking_{timestamp}.png')\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# Function to evaluate the best model on the validation set\n",
    "# ------------------------------\n",
    "def evaluate_best_model(best_model_path, val_img_dir, val_csv, best_config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the model with the same hyperparameters\n",
    "    model = get_model(\n",
    "        model_name='convnext_tiny',\n",
    "        num_classes=15,\n",
    "        dropout_rate=best_config['dropout_rate'],\n",
    "        stochastic_depth_prob=best_config['stochastic_depth_prob']\n",
    "    )\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create validation dataset and loader\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_dataset = RegionDataset(val_csv, val_img_dir, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=best_config['batch_size'], shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Evaluate\n",
    "    final_accuracy = evaluate_model(model, val_loader, device)\n",
    "    print(f\"\\n--- Final Evaluation of Best Model ---\")\n",
    "    print(f\"Best model parameters:\")\n",
    "    for param, value in best_config.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"Model path: {best_model_path}\")\n",
    "    print(f\"Final validation accuracy: {final_accuracy:.4f}\")\n",
    "    \n",
    "    return final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:59:12.048794Z",
     "iopub.status.busy": "2025-05-05T12:59:12.048591Z",
     "iopub.status.idle": "2025-05-05T12:59:12.068372Z",
     "shell.execute_reply": "2025-05-05T12:59:12.067723Z",
     "shell.execute_reply.started": "2025-05-05T12:59:12.048777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(train_img_dir, train_csv, val_img_dir, val_csv):\n",
    "    print(\"Starting hyperparameter testing...\")\n",
    "    \n",
    "    # Test hyperparameter combinations\n",
    "    results, results_df, best_config, best_model_path = test_hyperparameter_combinations(\n",
    "        train_img_dir, train_csv, val_img_dir, val_csv\n",
    "    )\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_results(results, results_df)\n",
    "    \n",
    "    # Evaluate the best model on the validation set\n",
    "    final_accuracy = evaluate_best_model(best_model_path, val_img_dir, val_csv, best_config)\n",
    "    \n",
    "    print(\"\\n--- Hyperparameter Testing Completed ---\")\n",
    "    print(f\"Best configuration: {best_config}\")\n",
    "    print(f\"Best model path: {best_model_path}\")\n",
    "    print(f\"Final validation accuracy: {final_accuracy:.4f}\")\n",
    "    \n",
    "    return best_config, best_model_path, final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:59:12.069639Z",
     "iopub.status.busy": "2025-05-05T12:59:12.069360Z",
     "iopub.status.idle": "2025-05-05T12:59:12.088065Z",
     "shell.execute_reply": "2025-05-05T12:59:12.087408Z",
     "shell.execute_reply.started": "2025-05-05T12:59:12.069615Z"
    },
    "id": "ED-03joavwvh",
    "outputId": "d4d923e7-9a36-4e4b-e0c5-739a4cb5a7f0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_img_dir = '/kaggle/input/images/images_train/images_train'\n",
    "train_csv = '/kaggle/input/labels/labels_train_updated.csv'\n",
    "val_img_dir = '/kaggle/input/images/images_val/images_val'\n",
    "val_csv = '/kaggle/input/labels/labels_val_updated.csv'\n",
    "\n",
    "main(train_img_dir, train_csv, val_img_dir, val_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(best_model_path, val_img_dir, test_img_dir, val_csv, best_config, submission_filename):\n",
    "    import os\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    from PIL import Image\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision import transforms\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the model with the same hyperparameters\n",
    "    model = get_model(\n",
    "        model_name='convnext_tiny',\n",
    "        num_classes=15,\n",
    "        dropout_rate=best_config['dropout_rate'],\n",
    "        stochastic_depth_prob=best_config['stochastic_depth_prob']\n",
    "    )\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create validation dataset and loader\n",
    "    val_transforms = transforms.Compose([\n",
    "        # Use a center crop instead of resize to maintain aspect ratio while getting fixed size\n",
    "        transforms.CenterCrop(256),  # This will only crop if image is larger than 256x256\n",
    "        transforms.Pad(0, padding_mode='reflect'),  # Add padding if needed to make square\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_dataset = RegionDataset(val_csv, val_img_dir, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=best_config['batch_size'], shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Evaluate\n",
    "    final_accuracy = evaluate_model(model, val_loader, device)\n",
    "    print(f\"\\n--- Final Evaluation of Best Model ---\")\n",
    "    print(f\"Best model parameters:\")\n",
    "    for param, value in best_config.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"Model path: {best_model_path}\")\n",
    "    print(f\"Final validation accuracy: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Generate predictions for validation set\n",
    "    val_predictions = []\n",
    "    val_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Convert to integers and move to CPU\n",
    "            predicted_classes = predicted.cpu().numpy() + 1  # Add 1 since Region_ID is 1-15\n",
    "            \n",
    "            # Get actual indices from validation dataset\n",
    "            batch_ids = list(range(i * best_config['batch_size'], \n",
    "                             min((i + 1) * best_config['batch_size'], len(val_dataset))))\n",
    "            \n",
    "            val_predictions.extend(predicted_classes)\n",
    "            val_ids.extend(batch_ids)\n",
    "    \n",
    "    # Create DataFrame for validation predictions\n",
    "    val_df = pd.DataFrame({\n",
    "        'id': val_ids,\n",
    "        'Region_ID': val_predictions\n",
    "    })\n",
    "    \n",
    "    # Create and process test dataset\n",
    "    # For test dataset, we may not have labels, so we'll create a custom dataset\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, img_dir, transform=None, img_size=256, expected_count=369):\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "            self.img_size = img_size\n",
    "            \n",
    "            # Look for all common image file types with case insensitive extensions\n",
    "            self.image_files = []\n",
    "            for extension in ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']:\n",
    "                self.image_files.extend([f for f in os.listdir(img_dir) \n",
    "                                       if f.lower().endswith(extension)])\n",
    "            \n",
    "            # Sort to maintain consistent order\n",
    "            self.image_files = sorted(self.image_files)\n",
    "            \n",
    "            print(f\"Found {len(self.image_files)} test images in {img_dir}\")\n",
    "            \n",
    "            # Check if we found the expected number of images\n",
    "            if len(self.image_files) != expected_count:\n",
    "                print(f\"WARNING: Expected {expected_count} test images but found {len(self.image_files)}\")\n",
    "                # List all files in directory to help diagnose the issue\n",
    "                all_files = os.listdir(img_dir)\n",
    "                print(f\"Total files in directory: {len(all_files)}\")\n",
    "                # Check for hidden files or unusual extensions\n",
    "                unusual_files = [f for f in all_files if f not in self.image_files]\n",
    "                if unusual_files:\n",
    "                    print(f\"Files not recognized as images: {unusual_files[:10]}\")\n",
    "                    if len(unusual_files) > 10:\n",
    "                        print(f\"...and {len(unusual_files) - 10} more\")\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.image_files)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            img_name = os.path.join(self.img_dir, self.image_files[idx])\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "            \n",
    "            # Get original size\n",
    "            width, height = image.size\n",
    "            \n",
    "            # Only resize if image is larger than target size\n",
    "            if width > self.img_size or height > self.img_size:\n",
    "                # Preserve aspect ratio while ensuring dimensions don't exceed img_size\n",
    "                if width > height:\n",
    "                    new_width = self.img_size\n",
    "                    new_height = int(height * (self.img_size / width))\n",
    "                else:\n",
    "                    new_height = self.img_size\n",
    "                    new_width = int(width * (self.img_size / height))\n",
    "                \n",
    "                image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image\n",
    "    \n",
    "    # Create test dataset and loader\n",
    "    test_dataset = TestDataset(test_img_dir, transform=val_transforms, expected_count=369)\n",
    "    \n",
    "    # If we still don't have all 369 test images, handle this situation\n",
    "    if len(test_dataset) < 369:\n",
    "        print(f\"WARNING: Will add {369 - len(test_dataset)} placeholder entries for missing test images\")\n",
    "        # We'll continue with the available images, but make sure we generate predictions\n",
    "        # for the full expected test set size\n",
    "    # Modify the test loader to use a custom collate function that handles different sized images\n",
    "    def custom_collate_fn(batch):\n",
    "        # Find the max dimensions in this batch\n",
    "        max_h = max([img.shape[1] for img in batch]) \n",
    "        max_w = max([img.shape[2] for img in batch])\n",
    "        \n",
    "        # Pad each image to the max dimensions\n",
    "        padded_batch = []\n",
    "        for img in batch:\n",
    "            c, h, w = img.shape\n",
    "            # Create new tensor with max dimensions\n",
    "            padded_img = torch.zeros((c, max_h, max_w), dtype=img.dtype)\n",
    "            # Copy the original image data\n",
    "            padded_img[:, :h, :w] = img\n",
    "            padded_batch.append(padded_img)\n",
    "        \n",
    "        # Stack the padded images\n",
    "        return torch.stack(padded_batch)\n",
    "        \n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_config['batch_size'], \n",
    "                            shuffle=False, num_workers=2, \n",
    "                            collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # Generate predictions for test set\n",
    "    test_predictions = []\n",
    "    test_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Convert to integers and move to CPU\n",
    "            predicted_classes = predicted.cpu().numpy() + 1  # Add 1 since Region_ID is 1-15\n",
    "            \n",
    "            # Calculate batch IDs starting from the end of validation set\n",
    "            start_idx = len(val_dataset)\n",
    "            batch_ids = list(range(start_idx + i * best_config['batch_size'], \n",
    "                             start_idx + min((i + 1) * best_config['batch_size'], len(test_dataset))))\n",
    "            \n",
    "            test_predictions.extend(predicted_classes)\n",
    "            test_ids.extend(batch_ids)\n",
    "    \n",
    "    # Check if we need to add placeholder predictions for missing test images\n",
    "    total_test_samples = 369\n",
    "    if len(test_predictions) < total_test_samples:\n",
    "        missing_count = total_test_samples - len(test_predictions)\n",
    "        print(f\"Adding {missing_count} placeholder predictions for missing test images\")\n",
    "        \n",
    "        # Use the most common class as placeholder (more likely to be correct than random)\n",
    "        if test_predictions:\n",
    "            from collections import Counter\n",
    "            most_common_class = Counter(test_predictions).most_common(1)[0][0]\n",
    "        else:\n",
    "            most_common_class = 1  # Default if we have no predictions at all\n",
    "            \n",
    "        # Generate sequential IDs for missing entries\n",
    "        start_idx = len(val_dataset) + len(test_predictions)\n",
    "        missing_ids = list(range(start_idx, start_idx + missing_count))\n",
    "        \n",
    "        # Extend our predictions and IDs\n",
    "        test_predictions.extend([most_common_class] * missing_count)\n",
    "        test_ids.extend(missing_ids)\n",
    "    \n",
    "    # Create DataFrame for test predictions\n",
    "    test_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'Region_ID': test_predictions\n",
    "    })\n",
    "    \n",
    "    # Combine validation and test predictions\n",
    "    submission_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(submission_filename, index=False)\n",
    "    print(f\"Submission file created: {submission_filename}\")\n",
    "    print(f\"Total entries: {len(submission_df)} (Validation: {len(val_df)}, Test: {len(test_df)})\")\n",
    "    \n",
    "    return final_accuracy, submission_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "best_model_path = '/kaggle/input/best-model/best_epoch_16_acc_0.9675.pth'\n",
    "val_img_dir = '/kaggle/input/images/images_val/images_val'\n",
    "test_img_dir = '/kaggle/input/images-test/images_test'  # Add path to test images\n",
    "val_csv = '/kaggle/input/labels/labels_val_updated.csv'\n",
    "best_config = {\n",
    "    'batch_size': 32,\n",
    "    'dropout_rate': 0.5,\n",
    "    'stochastic_depth_prob': 0.5,\n",
    "}\n",
    "# Replace with your roll number and version\n",
    "your_roll_no = '2022101113'\n",
    "version = '2'\n",
    "submission_filename = f'{your_roll_no}_{version}.csv'\n",
    "final_accuracy, submission_df = evaluate_best_model(\n",
    "    best_model_path, val_img_dir, test_img_dir, val_csv, best_config, submission_filename\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7127285,
     "sourceId": 11382673,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7127305,
     "sourceId": 11382709,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7199224,
     "sourceId": 11486057,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7319054,
     "sourceId": 11662454,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
